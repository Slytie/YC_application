# Progression to Quantum Neural Processes

This repository contains a collection of AI models and methodologies implemented in Python to solve the problem of looking for a AI model that provides an invertible stochastic mapping in a coordinate frame. 

Please note that the code was not cleaned up before putting into the repository, the research into different models was done quickly to efficiently test different approaches

## Latent CNP
- Focuses on Conditional Neural Processes with latent variables for efficient learning from context data and uncertainty representation.

## Quantum coin
- Simulates a quantum walk on a grid, demonstrating quantum computing concepts like superposition, quantum gates, and environmental interactions.

## Dirichlet Processes
- Implements a multidimensional Dirichlet Process using stick-breaking processes for clustering or density estimation with an unknown number of underlying groups.

## KDE (Kernel Density Estimation)
- Provides utilities for generating and analyzing discrete probability distributions, useful for understanding data distributions and statistical modeling.

## Gaussian CNN
- Combines Convolutional Neural Networks with Gaussian processes for uncertainty modeling in tasks like regression or classification.

## Crank Nelson Net
- Explores advanced numerical solutions to create learnable stochastic differential equations using modern neural network approaches.

## Cause Effect Probabilistic Programming
- Models relationships between cause and effect variables using probabilistic programming techniques with PyMC3.

## EncoderUnet
- Implements a modified U-Net architecture focusing on the encoder segment for modeling discrete distributions.

## EMVAE (Expectation-Maximization Variational AutoEncoder)
- Combines attention mechanisms with variational autoencoder principles for complex sequence-based learning tasks.

## Probabilistic Programming
- Defines a stochastic process model using Pyro for tasks requiring uncertainty quantification and model flexibility.

## Extending GP to Include Multi-Model Distributions
- Enhances Gaussian Process models to handle complex and heterogeneous data by accommodating multi-modal distributions.

## Bayesian Conditional Neural Processes
- Combines Bayesian principles with neural processes for tasks requiring adaptation to new data and uncertainty quantification.

